{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YT live chat automod\n",
    "Credentials generation :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.credentials import Credentials\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auth generation\n",
    "used to generate crendentials file with the client credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "# Remplacez par vos propres informations\n",
    "scopes = ['https://www.googleapis.com/auth/youtube']\n",
    "client_secrets_file = 'client_secret.json'\n",
    "\n",
    "def main():\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(\n",
    "        client_secrets_file,\n",
    "        scopes=scopes,\n",
    "        redirect_uri='urn:ietf:wg:oauth:2.0:oob')\n",
    "\n",
    "    auth_url, _ = flow.authorization_url(prompt='consent')\n",
    "\n",
    "    print('Please go to this URL and authorize access:', auth_url)\n",
    "    code = input('Enter the authorization code: ')\n",
    "    flow.fetch_token(code=code)\n",
    "\n",
    "    credentials = flow.credentials\n",
    "\n",
    "    # Creation of a crendentials file\n",
    "    with open(\"credentials.json\", \"w\") as f:\n",
    "        f.write(credentials.to_json())\n",
    "    \n",
    "    print(credentials.to_json())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class request\n",
    "Class to handle youtube request since youtube api doesn't provide a request object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Request:\n",
    "    \"\"\" Class Request handling youtube request as an object \"\"\"\n",
    "    def __init__(self, requestType,part=None, id=None, chart=None, regionCode=None, maxResults=None, pageToken=None, videoId=None, liveChatId=None):\n",
    "        self.requestType = requestType\n",
    "        self.part = part\n",
    "        self.id = id\n",
    "        self.chart = chart\n",
    "        self.regionCode = regionCode\n",
    "        self.maxResults = maxResults\n",
    "        self.pageToken = pageToken\n",
    "        self.videoId = videoId\n",
    "        self.liveChatId = liveChatId\n",
    "        \n",
    "    def execute(self):\n",
    "        param = vars(self) # Fetch class attributes\n",
    "        param = {x:y for x,y in list(param.items())[1:] if y} # Delete requestType ([1:]) and None attributes\n",
    "        \n",
    "        request = self.requestType.list(**param)\n",
    "        return request.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger \n",
    "Setup logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logFolder = 'logs'\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "file_handler = logging.FileHandler(f'{logFolder}/automod.log')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(levelname)s : %(asctime)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live chat ID from video ID\n",
    "Used to get the chat ID from Live ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_liveChat(youtube, video_id) -> dict:\n",
    "    try:\n",
    "        video_response = youtube.videos().list(\n",
    "            part=\"liveStreamingDetails\",\n",
    "            id=video_id\n",
    "        ).execute()\n",
    "        \n",
    "        video:dict = video_response.get('items', [])[0]\n",
    "        videoData = {\n",
    "            \"id\" : video.get('id', \"\"),\n",
    "            \"startTime\" : video.get(\"liveStreamingDetails\", {}).get(\"actualStartTime\", \"\"),\n",
    "            \"concurrentViewers\" : int(video.get(\"liveStreamingDetails\", {}).get(\"concurrentViewers\", 0)),\n",
    "            \"chatID\" : video.get(\"liveStreamingDetails\", {}).get(\"activeLiveChatId\", \"\"),\n",
    "        }\n",
    "        \n",
    "        if videoData['chatID'] == \"\":\n",
    "            raise Exception(\"This live has not chat available\")\n",
    "        return videoData\n",
    "    except Exception as e:\n",
    "        print(e)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Channel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_channel_data(channel_data: dict):\n",
    "    \"\"\" Structure raw channel data \"\"\"\n",
    "    data = {\n",
    "        \"channel_name\": channel_data.get('snippet', {}).get('title'),\n",
    "        \"channel_id\": channel_data.get('id'),\n",
    "        \"country\": channel_data.get('snippet', {}).get('country',\"\"),\n",
    "        **{k:int(v) for k,v in channel_data.get('statistics', {}).items() if k != \"hiddenSubscriberCount\"},\n",
    "        \"topics\": [wikilink.split('/')[-1] for wikilink in channel_data.get('topicDetails', {}).get('topicCategories', [])],\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_data(youtube, channel_id:str) -> dict[str|dict]:\n",
    "    \"\"\" Request (by id) for most important channel stats \"\"\"\n",
    "    request = Request(\n",
    "        requestType=youtube.channels(),\n",
    "        part=\"snippet,contentDetails,statistics,topicDetails\",\n",
    "        id=channel_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    rawData = response.get('items', [])[0]\n",
    "    return format_channel_data(rawData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gorgias functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gorgias_auth.json\") as f:\n",
    "    gorgias_auth = json.load(f)\n",
    "\n",
    "BASE_GORGIAS_URL = gorgias_auth[\"url\"]\n",
    "# Exemple of a function using the prolog API to prove a policy option\n",
    "def queryGorgias(facts=[], gorgiasFile=\"\", query=\"\", auth=(gorgias_auth[\"user\"], gorgias_auth[\"pass\"])):\n",
    "    # query = \"challenge(Agent, Resource)\"  # prolog query\n",
    "    data = {\n",
    "        \"facts\": facts,  # Facts as list of str\n",
    "        \"gorgiasFiles\": [\n",
    "            gorgiasFile  #  Gorgias file name preceded by project name: project/file.pl\n",
    "        ],\n",
    "        \"query\": query,\n",
    "        \"resultSize\": 1\n",
    "    }\n",
    "\n",
    "    r = requests.post(f\"{BASE_GORGIAS_URL}/GorgiasQuery\", json=data, auth=auth)\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        print(\"error\")\n",
    "        return False\n",
    "    return r.json()\n",
    "\n",
    "# Exemple of a function using the prolog API to create a project\n",
    "def createProject(project_name = \"\", auth=(\"elnidala\", \"GorgiasPass!\")):\n",
    "    r = requests.post(f\"{BASE_GORGIAS_URL}/createProject?project_name={project_name}\", auth=auth)\n",
    "    if r.status_code != 200:\n",
    "        print(\"error\")\n",
    "        return False\n",
    "    return r.json()\n",
    "\n",
    "# Exemple of a function using the prolog API to add a file\n",
    "def addFile(file = \"\", project= \"\", type= \"\", auth=(\"elnidala\", \"GorgiasPass!\")):\n",
    "    files = {'file': open(f'{file}', 'rb')}\n",
    "\n",
    "    r = requests.post(f\"{BASE_GORGIAS_URL}/addFile?project={project}&type={type}\", files=files, auth=auth)\n",
    "    if r.status_code != 200:\n",
    "        print(r.status_code)\n",
    "        return False\n",
    "    return r.json() \n",
    "\n",
    "# Exemple of a function using the prolog API to delete a project\n",
    "def deleteProject(project = \"\", auth=(\"elnidala\", \"GorgiasPass!\")):\n",
    "    r = requests.post(f\"{BASE_GORGIAS_URL}/deleteProject?project={project}\", auth=auth)\n",
    "    if r.status_code != 200:\n",
    "        print(\"error\")\n",
    "        return False\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "# Exemple of a function using the prolog API to delete a file\n",
    "def deleteFile(filename = \"\", project=\"\", auth=(\"elnidala\", \"GorgiasPass!\")):\n",
    "    r = requests.post(f\"{BASE_GORGIAS_URL}/deleteFile?filename={filename}.pl&project={project}\", auth=auth)\n",
    "    if r.status_code != 200:\n",
    "        print(\"error\")\n",
    "        return False\n",
    "    return r.json() \n",
    "\n",
    "\n",
    "def initializeGorgias(projectName, policyFile):\n",
    "    \"\"\" Creates the project and add the file \"\"\"\n",
    "    if not(createProject(projectName) == 'OK' and addFile(policyFile, projectName, \"gorgias\") == ['OK']):\n",
    "        raise Exception('Failed to initialize')\n",
    "    \n",
    "#Returns the result of the query\n",
    "def askGorgias(facts = [], projectName=\"\", policyFile=\"\"):\n",
    "    response = queryGorgias(facts=facts, query=f\"action(X)\", gorgiasFile=f\"{projectName}/{policyFile}\")\n",
    "    try :\n",
    "        return response.get(\"result\", [])[0].get('variables', {}).get(\"X\", \"\") \n",
    "    except Exception:\n",
    "        print(response)\n",
    "        # raise Exception(\"Invalid Facts\")\n",
    "    \n",
    "def terminateGorgias(projectName):\n",
    "    \"\"\" Delete the project \"\"\"\n",
    "    if not(deleteProject(projectName) == 'OK'):\n",
    "        raise Exception('Failed to delete')\n",
    "   \n",
    "   \n",
    "# initializeGorgias(projectName, policyFile)\n",
    "# askGorgias([\"\", \"negative_message\"], projectName, policyFile)\n",
    "# terminateGorgias(projectName, policyFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat main function\n",
    "timeout, ban and unban functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeout_user(youtube, liveChatId, user_id, duration=360):\n",
    "    request = youtube.liveChatBans().insert(\n",
    "        part=\"snippet\",\n",
    "        body={\n",
    "          \"snippet\": {\n",
    "            \"liveChatId\": liveChatId,\n",
    "            \"type\": \"temporary\",\n",
    "            \"banDurationSeconds\": duration,\n",
    "            \"bannedUserDetails\": {\n",
    "              \"channelId\": user_id\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    )\n",
    "    response = request.execute()\n",
    "    ban_id = response.get('id', \"\")\n",
    "    print(response)\n",
    "    \n",
    "def perma_ban_user(youtube, liveChatId, user_id):\n",
    "  request = youtube.liveChatBans().insert(\n",
    "        part=\"snippet\",\n",
    "        body={\n",
    "          \"snippet\": {\n",
    "            \"liveChatId\": liveChatId,\n",
    "            \"type\": \"permanent\",\n",
    "            \"bannedUserDetails\": {\n",
    "              \"channelId\": user_id\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    )\n",
    "  response = request.execute()\n",
    "  ban_id = response.get('id',  \"\")\n",
    "  print(response)\n",
    "  \n",
    "def unban_user(youtube, ban_id):\n",
    "  request = youtube.liveChatBans().delete(\n",
    "        id=ban_id\n",
    "    )\n",
    "  request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_messageList(messages: list[dict]) -> pd.DataFrame:\n",
    "    return \"\".join([f\"{el['author']} : {el['message']}\\n\" for el in messages])\n",
    "\n",
    "def get_message_info(items:list[dict]) -> pd.DataFrame:\n",
    "    data = []\n",
    "    for item in items:\n",
    "        data.append({\n",
    "        \"username\" : item.get('authorDetails', {}).get('displayName', \"\"),\n",
    "        \"message_id\": item.get('id', \"\"),\n",
    "        \"message\" : item.get('snippet', {}).get('displayMessage', \"\"),\n",
    "        \"channel_id\" : item.get('snippet', {}).get('authorChannelId', \"\"),\n",
    "        \"publishedAt\" : item.get('snippet', {}).get('publishedAt', \"\")\n",
    "    })\n",
    "    # messages = pd.DataFrame(data)\n",
    "    # logger.debug(messages.columns)\n",
    "    # messages[\"publishedAt\"] = pd.to_datetime(messages[\"publishedAt\"])\n",
    "    # return messages.sort_values(by='publishedAt')\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_logs(live_chat_id):\n",
    "    \"\"\" Contains every known user \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(f\"{logFolder}/{live_chat_id}.csv\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        columns = ['username', \"last_msg_id\", 'last_msg', \"channel_id\", 'nb_msg', 'nb_ban', 'total_timeout_time']\n",
    "        return pd.DataFrame(columns=columns) # Empty Dataframe\n",
    "      \n",
    "def update_known_users(row: pd.Series, messages:pd.DataFrame):\n",
    "    msg = messages.copy()\n",
    "    try:\n",
    "        # Drop de tous les messages précédent le dernier message vu\n",
    "        if row['last_msg_id'] in msg['message_id'].to_list():\n",
    "            # print(\"last message here\")\n",
    "            drop_index:pd.Index = msg.loc[msg['message_id'] == row['last_msg_id']].index\n",
    "            msg = msg.drop(msg[(msg['channel_id'] == row['channel_id']) & (msg.index <= drop_index[0])].index)\n",
    "        \n",
    "        # Si l'id est présentes dans les derniers messages \n",
    "        if row['channel_id'] in msg['channel_id'].to_list():\n",
    "            row[\"last_msg\"] = msg[msg['channel_id'] == row[\"channel_id\"]].groupby('channel_id').last()[\"message\"].iloc[-1]\n",
    "            # print(f\"{row['username']} - Added {len(msg[msg['channel_id'] == row['channel_id']])} messages to {row['nb_msg']}\")\n",
    "            row[\"nb_msg\"] += len(msg[msg['channel_id'] == row['channel_id']])\n",
    "            row['last_msg_id'] = msg.loc[msg['channel_id'] == row['channel_id'], 'message_id'].iloc[-1]\n",
    "        return row\n",
    "    except Exception:\n",
    "        print(\"\\033[92mCrashed \\033[0m\")\n",
    "        # print(messages.columns + \"\\033[92m <- Crashed \\033[0m\")\n",
    "\n",
    "def update_chat_logs(messages: pd.DataFrame, chat_logs: pd.DataFrame) -> pd.DataFrame:\n",
    "    # +1 au nombre de message pour les utilisateurs déjà présents\n",
    "    # chat_logs.loc[(chat_logs['channel_id'].isin(messages['channel_id']) & ~chat_logs['last_msg_id'].isin(messages['message_id'])), \"nb_msg\"] += 1\n",
    "    # print(f\"Number of known users : {len(chat_logs[chat_logs['channel_id'].isin(messages['channel_id'])])}\")\n",
    "    \n",
    "    chat_logs = chat_logs.apply(lambda row: update_known_users(row, messages), axis=1)\n",
    "    \n",
    "    # ajout de la ligne pour utilisateurs non présents\n",
    "    unknown_users = messages[~messages['channel_id'].isin(chat_logs['channel_id'])].copy()\n",
    "    unknown_users.drop([\"publishedAt\"], axis=1)\n",
    "    unknown_users.rename(columns={'message_id': 'last_msg_id', \"message\" : 'last_msg'}, inplace=True)\n",
    "    unknown_users = unknown_users.reindex(columns=chat_logs.columns)\n",
    "    unknown_users['nb_msg'] = 1 # Initialisation du nombre de message à 1\n",
    "    \n",
    "    # Cas particulier où plusieurs messages du même utilisateur inconnu arrivent en même temps \n",
    "    unknown_users = unknown_users.groupby('channel_id').agg({'last_msg_id': 'last', 'nb_msg': 'sum', 'username': 'last', 'last_msg':'last'}).reset_index()\n",
    "    \n",
    "    unknown_users['nb_ban'] = 0\n",
    "    unknown_users['total_timeout_time'] = 0\n",
    "    \n",
    "    return pd.concat([chat_logs, unknown_users])\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# text_example = \"Horrible Gameplay\"\n",
    "# result = process_message(\n",
    "#     text_example,\n",
    "#     pipelines={\n",
    "#         'insult': insult_detector,\n",
    "#         'sentiment': sentiment_detector,\n",
    "#         'emotion': emotion_detector\n",
    "#     },\n",
    "#     config=config\n",
    "# )\n",
    "\n",
    "# print(\"Processing Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handleling Messages\n",
    "Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment import insult_detector, sentiment_detector, emotion_detector, config, process_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout_lvl = { # To change by user\n",
    "    \"sanction_level_one\" : 600,\n",
    "    \"sanction_level_two\": 3600,\n",
    "    \"sanction_level_three\": 86400\n",
    "}\n",
    "\n",
    "\n",
    "def analyse_message(youtube, row: pd.Series, live_id, chat_logs:pd.DataFrame):\n",
    "    projectName = \"TER2024\"\n",
    "    policyFile = \"decision.pl\"\n",
    "    \n",
    "    logs = chat_logs.copy(deep=True)\n",
    "    nb_bans = logs.set_index('channel_id').loc[row['channel_id'], 'nb_ban'] if row['channel_id'] in logs['channel_id'].values else 0\n",
    "    \n",
    "    try:\n",
    "        facts = process_message(\n",
    "            row[\"message\"],\n",
    "            pipelines = {\n",
    "                'insult': insult_detector,\n",
    "                'sentiment': sentiment_detector,\n",
    "                'emotion': emotion_detector\n",
    "            },\n",
    "            config = config,\n",
    "            timeout = nb_bans\n",
    "        )\n",
    "        \n",
    "        punish_id = askGorgias(facts, projectName, policyFile)\n",
    "        logger.debug(f\"{row['message']} + {facts} -> {punish_id}\")\n",
    "        print(f\"\\\"{row['message']}\\\" + {facts} -> {punish_id}\")\n",
    "        \n",
    "        punishements = {\"no_nothing\" : None,\n",
    "            \"warning\": None, #Insert message ?\n",
    "            \"sanction_level_one\": lambda: timeout_user(youtube, live_id, row[\"channel_id\"], timeout_lvl[\"sanction_level_one\"]), \n",
    "            \"sanction_level_two\": lambda: timeout_user(youtube, live_id, row[\"channel_id\"], timeout_lvl[\"sanction_level_two\"]), \n",
    "            \"sanction_level_three\": lambda: timeout_user(youtube, live_id, row[\"channel_id\"], timeout_lvl[\"sanction_level_three\"]), \n",
    "            \"ban_user\" : lambda: perma_ban_user(youtube, live_id, row[\"channel_id\"])\n",
    "            }\n",
    "        \n",
    "        if punishements[punish_id]: \n",
    "            punishements[punish_id]() # Calls the function\n",
    "            chat_logs.loc[chat_logs['channel_id'] == row['channel_id'], 'nb_ban'] += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        # print(row.to_dict())\n",
    "        print(e)\n",
    "        print()\n",
    "        pass\n",
    "    finally:\n",
    "        return row    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def handle_messages(youtube, messages: pd.DataFrame, live_id, chat_logs: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not messages.empty:\n",
    "        chat_logs = update_chat_logs(messages, chat_logs)\n",
    "        # analyse_message(youtube, messages, live_id, chat_logs)\n",
    "        \n",
    "        logger.debug(f\"Added {len(messages)} msg\")\n",
    "        print(f\"\\033[92mAdded {len(messages)} msg\\033[0m\")\n",
    "        \n",
    "        # messages.apply(lambda el: print(f\"{el['username']} : {el['message']}\"), axis=1)\n",
    "        \n",
    "        \n",
    "        \"\"\" Analyse every single message and decide to ban it or not\"\"\"\n",
    "        messages.apply(lambda row: analyse_message(youtube, row, live_id, chat_logs), axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return chat_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching chat messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_live_chat_messages(youtube, live_chat_id):\n",
    "    chat_logs = get_chat_logs(live_chat_id)\n",
    "    \n",
    "    request = Request(youtube.liveChatMessages(), liveChatId=live_chat_id, part='id,snippet,authorDetails', pageToken=\"\")\n",
    "    response = request.execute()\n",
    "    \n",
    "    messages = get_message_info(response.get('items', []))\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            chat_logs = await handle_messages(youtube, messages, live_chat_id, chat_logs)\n",
    "            # await process_messages(youtube, messages, live_chat_id)\n",
    "            \n",
    "            # Intervalle de temps donné avant la prochaine request\n",
    "            logger.debug(f'PollingRate : {response.get(\"pollingIntervalMillis\", 5000)}')\n",
    "            await asyncio.sleep(response.get(\"pollingIntervalMillis\", 5000) / 1000.0)  \n",
    "            \n",
    "            request.pageToken = response.get(\"nextPageToken\", \"\")\n",
    "            response = request.execute()\n",
    "            \n",
    "            messages = get_message_info(response.get('items', []))\n",
    "            \n",
    "    except asyncio.CancelledError: #interruption du programme\n",
    "        print(\"interrupt\")\n",
    "        chat_logs.to_csv(f\"{logFolder}/{live_chat_id}.csv\", index=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration et authentification de l'API YouTube\n",
    "projectName = \"TER2024\"\n",
    "policyFile = \"decision.pl\"\n",
    "credentials = Credentials.from_authorized_user_file('credentials.json')\n",
    "youtube = build('youtube', 'v3', credentials=credentials, developerKey='AIzaSyCCdz9UNwtWNJGFL_Q9EghMOO0u5O5qYlg')\n",
    "\n",
    "videoData = get_liveChat(youtube, 'oXGELAErKx0')\n",
    "\n",
    "live_chat_id = videoData[\"chatID\"]\n",
    "print(f\"Awaiting messages on chat ID: {live_chat_id}\")\n",
    "\n",
    "# initializeGorgias(projectName, policyFile)\n",
    "\n",
    "# Démarrer la boucle de récupération des messages\n",
    "# try:\n",
    "await fetch_live_chat_messages(youtube, live_chat_id) \n",
    "# except Exception:\n",
    "#     pass\n",
    "# finally:\n",
    "# print('Terminate')\n",
    "# terminateGorgias(projectName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"This is amazing, I love how you're explaining everything!\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"You're so dumb, how do you not get this?\" detected as ['very_toxic_message'] -> sanction_level_three\n",
      "\"Can you please show that part again?\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"Wow, this stream is boring.\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"You're doing a great job, keep it up!\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"I can't believe you're this stupid.\" detected as ['very_toxic_message'] -> sanction_level_three\n",
      "\"This is the best stream ever!\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"Why are you even trying, you suck at this.\" detected as ['very_toxic_message'] -> sanction_level_three\n",
      "\"I'm so happy I found this stream.\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"Your voice is really annoying.\" detected as ['toxic_message', 'negative_message', 'negative_high_intensity_emotion'] -> sanction_level_two\n",
      "\"Great content, very informative!\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"I hope you fail at everything you do.\" detected as ['toxic_message', 'negative_message', 'negative_high_intensity_emotion'] -> sanction_level_two\n",
      "\"Thanks for answering my question, you're awesome!\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"This is a waste of time.\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"You're such a kind and thoughtful person.\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"Nobody cares about what you're saying.\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"I'm learning so much from you!\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"You're the worst streamer ever.\" detected as ['very_toxic_message'] -> sanction_level_three\n",
      "\"Can you give me a shoutout?\" detected as ['not_toxic_message'] -> do_nothing\n",
      "\"Your setup looks really cool, love it!\" detected as ['not_toxic_message'] -> do_nothing\n"
     ]
    }
   ],
   "source": [
    "test_phrases = [\n",
    "    \"This is amazing, I love how you're explaining everything!\",\n",
    "    \"You're so dumb, how do you not get this?\",\n",
    "    \"Can you please show that part again?\",\n",
    "    \"Wow, this stream is boring.\",\n",
    "    \"You're doing a great job, keep it up!\",\n",
    "    \"I can't believe you're this stupid.\",\n",
    "    \"This is the best stream ever!\",\n",
    "    \"Why are you even trying, you suck at this.\",\n",
    "    \"I'm so happy I found this stream.\",\n",
    "    \"Your voice is really annoying.\",\n",
    "    \"Great content, very informative!\",\n",
    "    \"I hope you fail at everything you do.\",\n",
    "    \"Thanks for answering my question, you're awesome!\",\n",
    "    \"This is a waste of time.\",\n",
    "    \"You're such a kind and thoughtful person.\",\n",
    "    \"Nobody cares about what you're saying.\",\n",
    "    \"I'm learning so much from you!\",\n",
    "    \"You're the worst streamer ever.\",\n",
    "    \"Can you give me a shoutout?\",\n",
    "    \"Your setup looks really cool, love it!\"\n",
    "]\n",
    "\n",
    "projectName = \"TER2024\"\n",
    "policyFile = \"decision.pl\"\n",
    "for p in test_phrases:\n",
    "    facts = process_message(\n",
    "            p,\n",
    "            pipelines = {\n",
    "                'insult': insult_detector,\n",
    "                'sentiment': sentiment_detector,\n",
    "                'emotion': emotion_detector\n",
    "            },\n",
    "            config = config,\n",
    "            timeout = 0\n",
    "        )\n",
    "    \n",
    "    punish_id = askGorgias(facts, projectName, policyFile)   \n",
    "    print(f\"\\\"{p}\\\" detected as {facts} -> {punish_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
